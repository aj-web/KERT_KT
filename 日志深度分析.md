# DKT训练日志深度分析

## 一、关键观察

### 训练过程（Run 1）

| Epoch | Loss | Val AUC | Val ACC | 观察 |
|-------|------|---------|---------|------|
| 5 | 0.2049 | 0.5036 | 0.5826 | 损失开始下降 |
| 10 | 0.0104 | 0.5009 | 0.5650 | **损失大幅下降，但AUC几乎不变** |
| 15 | 0.0038 | 0.5018 | 0.5745 | **损失继续下降，AUC仍然0.50** |
| 测试 | - | **0.4999** | 0.5722 | **AUC接近随机猜测** |

### 问题诊断

#### 🔴 **严重问题：损失下降但AUC不提升**

**现象**：
- 损失从0.20快速降到0.0038（下降98%）
- 但Val AUC始终在0.50左右（几乎没有变化）
- 最终测试AUC=0.4999（几乎等于随机猜测0.5）

**这说明了什么？**

1. **模型没有学到有用的模式**
   - 损失下降可能是因为模型学到了一个简单的模式（比如总是预测接近0.5）
   - 这个模式在训练集上损失低，但在验证集上AUC不提升

2. **损失函数和AUC不匹配**
   - BCE损失可能在优化错误的目标
   - 或者模型输出分布有问题

3. **可能的数据泄露或标签问题**
   - 虽然标签分布正常，但可能存在其他问题

## 二、根本原因分析

### 可能原因1：DKT输入编码问题

当前DKT的输入编码：
```python
# 问题：answer编码太简单
answer_embeds = answer_seq.unsqueeze(-1).float()  # [batch, seq, 1]
answer_embeds = answer_embeds.expand(-1, -1, embed_dim)  # 只是简单扩展
```

**原始DKT论文的输入格式**应该是：
- 对于每个问题q和答案a，输入是：`[q * a, q * (1-a)]`
- 这相当于将问题编码为2*embed_dim的向量

**当前实现的问题**：
- 只是简单地将answer扩展，没有与question embedding交互
- 这可能导致模型无法有效利用answer信息

### 可能原因2：预测方式问题

当前实现：
```python
# 预测所有concepts，然后选择target_concept
concept_probs = self.forward(question_seq, answer_seq)  # [batch, n_concepts]
predictions = concept_probs[torch.arange(batch_size), target_concept]
```

**问题**：
- 如果target_concept的选择有问题，预测就会错误
- 需要验证target_concept是否正确对应target_question

### 可能原因3：训练策略问题

**观察**：
- 损失下降太快（15轮就降到0.0038）
- 这可能说明模型过拟合或学到了错误的模式

**可能的问题**：
- 学习率可能太大
- 没有正则化
- 训练数据可能有问题

## 三、验证步骤

### 步骤1：检查预测分布

运行以下代码检查模型预测：
```python
# 检查预测值分布
print("预测值分布:")
print(f"  均值: {predictions.mean():.4f}")
print(f"  标准差: {predictions.std():.4f}")
print(f"  最小值: {predictions.min():.4f}")
print(f"  最大值: {predictions.max():.4f}")
print(f"  中位数: {predictions.median():.4f}")

# 如果预测值总是接近0.5，说明模型没有学习
if abs(predictions.mean() - 0.5) < 0.05:
    print("[WARNING] 预测值接近0.5，模型可能没有学习")
```

### 步骤2：检查target_concept映射

```python
# 检查target_question和target_concept的对应关系
print("Target mapping检查:")
for i in range(10):
    q = target_question[i]
    c = target_concept[i]
    expected_c = q % n_concepts
    print(f"  Question {q} -> Concept {c} (expected: {expected_c})")
```

### 步骤3：检查训练损失vs验证损失

```python
# 同时记录训练集和验证集的损失
train_loss = ...
val_loss = ...

# 如果train_loss << val_loss，说明过拟合
if train_loss < val_loss * 0.1:
    print("[WARNING] 训练损失远小于验证损失，可能过拟合")
```

## 四、修复建议

### 修复1：改进DKT输入编码（最重要）

根据原始DKT论文，应该使用：
```python
# 正确的DKT输入编码
def encode_dkt_input(question_seq, answer_seq, embed_dim):
    batch_size, seq_len = question_seq.size()
    
    # 创建one-hot编码（或使用embedding）
    question_onehot = F.one_hot(question_seq, num_classes=n_questions).float()
    
    # DKT格式：[q*a, q*(1-a)]
    answer_expanded = answer_seq.unsqueeze(-1).float()  # [batch, seq, 1]
    answer_expanded = answer_expanded.expand(-1, -1, embed_dim)
    
    # 问题embedding
    question_embeds = self.question_embed(question_seq)
    
    # DKT输入：question * answer 和 question * (1-answer)
    input_correct = question_embeds * answer_expanded
    input_wrong = question_embeds * (1 - answer_expanded)
    
    lstm_inputs = torch.cat([input_correct, input_wrong], dim=-1)
    return lstm_inputs
```

### 修复2：验证target_concept映射

确保target_concept正确对应target_question：
```python
# 使用Q-matrix映射，而不是简单的取模
# target_concept = q_matrix[target_question].argmax()
```

### 修复3：调整训练策略

```python
# 1. 降低学习率
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# 2. 添加权重衰减
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)

# 3. 使用学习率调度
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)
```

### 修复4：添加训练监控

```python
# 同时监控训练集和验证集的AUC
train_auc = compute_auc(train_predictions, train_labels)
val_auc = compute_auc(val_predictions, val_labels)

print(f"Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}")

# 如果train_auc >> val_auc，说明过拟合
```

## 五、立即行动

### 优先级1：修复DKT输入编码

这是最可能的问题。需要按照原始DKT论文实现正确的输入编码。

### 优先级2：验证数据映射

检查target_question和target_concept的对应关系是否正确。

### 优先级3：调整训练参数

降低学习率，添加正则化，使用学习率调度。

## 六、预期修复后的结果

修复后，DKT应该能够：
- 训练50轮后AUC达到0.70+
- 训练100轮后AUC达到0.75-0.80
- 损失和AUC同步提升

