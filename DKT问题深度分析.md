# DKT模型问题深度分析（修复后仍然失败）

## 一、新日志观察（修复输入编码后）

### DKT结果（5次运行）

| Run | Epochs | Loss | Val AUC | Test AUC | Test ACC |
|-----|--------|------|---------|----------|----------|
| 1 | 15 | 0.0053 | 0.5014 | 0.4975 | 0.5701 |
| 2 | 15 | 0.0064 | 0.4964 | 0.5001 | 0.5710 |
| 3 | 13 | 0.0063 | 0.5004 | 0.5006 | 0.5710 |
| 4 | 20 | 0.0052 | 0.5016 | 0.4992 | 0.5765 |
| 5 | 11 | 0.0061 | 0.4985 | 0.5013 | 0.5768 |
| **均值** | - | - | - | **0.4997 ± 0.0013** | **0.5731 ± 0.0029** |

### 关键发现

1. **修复输入编码后，AUC仍然接近0.5**
   - 说明问题不仅仅是输入编码
   - 可能存在更深层的问题

2. **损失下降但AUC不提升的模式依然存在**
   - 损失：0.02 → 0.005（下降75%）
   - AUC：始终在0.50左右

3. **早停触发很快**
   - 11-20轮就早停
   - 因为AUC没有提升

## 二、可能的原因分析

### 原因1：Padding问题（最可能）

**问题**：
- Padding在左侧使用0值
- `question_id=0`会被embedding，这可能不是我们想要的
- 模型可能在学习利用padding位置的信息

**验证**：
```python
# 检查padding后的序列
print("Padding后的question_seq:", question_seq[0])
# 如果前面有很多0，说明padding有问题
```

**修复方案**：
1. 使用mask忽略padding位置
2. 或者使用特殊的padding token（如n_questions+1）

### 原因2：数据预处理问题

**可能的问题**：
- question_id可能从0开始，与padding的0冲突
- 需要检查数据中是否真的有question_id=0

**验证**：
```python
# 检查数据中的question_id范围
print("Question ID range:", df['question_id'].min(), df['question_id'].max())
# 如果min=0，说明确实有question_id=0，padding会冲突
```

### 原因3：模型架构问题

**可能的问题**：
- LSTM可能没有正确处理序列
- 输出层可能有问题
- 需要检查LSTM的hidden state是否正确

### 原因4：训练策略问题

**可能的问题**：
- 学习率可能不合适
- 可能需要更长的训练
- 早停策略可能太激进

## 三、立即需要检查的问题

### 检查1：Padding冲突

```python
# 检查question_id是否包含0
# 如果包含0，padding的0会与真实的question_id=0冲突
```

### 检查2：模型输出分布

```python
# 检查模型预测值的分布
# 如果总是接近0.5，说明模型没有学习
```

### 检查3：训练集vs验证集性能

```python
# 同时监控训练集AUC
# 如果训练集AUC也很低，说明模型本身有问题
# 如果训练集AUC高但验证集低，说明过拟合
```

## 四、建议的修复方案

### 方案1：修复Padding（最高优先级）

使用mask或特殊padding token：
```python
# 方案A：使用mask
# 方案B：使用n_questions作为padding token
padding_value = n_questions  # 而不是0
```

### 方案2：检查并修复数据

确保question_id不从0开始，或者使用1-based索引。

### 方案3：改进训练策略

- 降低学习率
- 增加训练轮数
- 调整早停策略

