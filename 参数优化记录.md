# 参数优化记录

> 本文档按照**实验轮次**递增更新，每轮包含：
> 0. 运行命令
> 1. 关键结果
> 2. 结果分析
> 3. 优化思路
> 4. 参数调整

---

## 实验 1  （baseline）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.2，L2 1e-5
- 最佳 Val AUC = **0.8183** @ epoch 2
- EarlyStopping epoch 12，最终 Val AUC = 0.7607

2. **结果分析**
- 训练损失持续下降，验证 AUC 从 0.8183 → 0.7607（过拟合明显）

3. **优化思路**
- 增强正则：提高 dropout、增大 L2

4. **参数调整**
| 参数 | 原 | 调整后 |
|------|----|--------|
| dropout | 0.2 | **0.3** |
| l2_lambda | 1e-5 | **1e-4** |

---

## 实验 2  （dropout 0.3 + L2 1e-4）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.3，L2 1e-4
- 最佳 Val AUC = **0.8205** @ epoch 2
- Val AUC 在 epoch 6 降至 0.7746
- 过拟合仍存在但略好于实验 1（下降幅度：5.7% → 5.6%）

2. **结果分析**
- 升级正则后最佳 AUC 略升（0.8183 → 0.8205）
- 过拟合速度稍放缓，但仍在 epoch 2 见顶
- 说明正则化力度仍不足 & 学习率过大

3. **优化思路**
- 再次抑制过拟合：
  1. **降低学习率** (0.001 → 0.0005)
  2. **进一步增大 dropout** (0.3 → 0.4)
  3. 适当缩短 Early-Stopping patience (10 → 7)

4. **参数调整**
| 参数 | 调整前 | 调整后 |
|------|--------|--------|
| lr_kt_pretrain | 0.001 | **0.0005** |
| lr_kt_finetune | 0.0005 | **0.00025** |
| dropout | 0.3 | **0.4** |
| patience | 10 | **7** |

---

## 实验 3  （dropout 0.4 + lr 0.0005 + patience 7）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.4，L2 1e-4，lr 0.0005
- 最佳 Val AUC = **0.8146** @ epoch 2
- Val AUC 在 epoch 3 降至 0.8082
- 训练在第4个epoch被中断（用户手动停止）

2. **结果分析**
- 降低学习率和增大dropout后，**过拟合问题依旧**，模型仍然在第2个epoch达到性能顶峰，然后迅速开始下降。
- 这说明简单的参数调整已达瓶颈，需要更高级的训练策略来稳定训练过程。

3. **优化思路**
- **引入学习率Warmup**：在训练初期使用一个非常小的学习率，然后逐渐增加到设定的初始学习率。这有助于模型在训练初期找到一个更稳定的收敛方向，避免过早陷入局部最优或过拟合。
- **使用学习率衰减（Scheduler）**：在Warmup之后，如果验证集性能在一定轮次内没有提升，就自动降低学习率，进行更精细的调优。

4. **参数调整**
| 参数 | 调整前 | 调整后 |
|------|--------|--------|
| `lr_kt_pretrain` | 0.0005 | **保持 0.0005** |
| `warmup_steps` | - | **4000** (约半个epoch) |
| `lr_scheduler` | - | **ReduceLROnPlateau** |
| `lr_decay_patience` | - | **3** |
| `lr_decay_factor` | - | **0.5** |

> **TODO 实验 4**：运行以上新参数，完成后补充结果。
