# 参数优化记录

> 本文档按照**实验轮次**递增更新，每轮包含：
> 0. 运行命令
> 1. 关键结果
> 2. 结果分析
> 3. 优化思路
> 4. 参数调整

---

## 实验 1  （baseline）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.2，L2 1e-5
- 最佳 Val AUC = **0.8183** @ epoch 2
- EarlyStopping epoch 12，最终 Val AUC = 0.7607

2. **结果分析**
- 训练损失持续下降，验证 AUC 从 0.8183 → 0.7607（过拟合明显）

3. **优化思路**
- 增强正则：提高 dropout、增大 L2

4. **参数调整**
| 参数 | 原 | 调整后 |
|------|----|--------|
| dropout | 0.2 | **0.3** |
| l2_lambda | 1e-5 | **1e-4** |

---

## 实验 2  （dropout 0.3 + L2 1e-4）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.3，L2 1e-4
- 最佳 Val AUC = **0.8205** @ epoch 2
- Val AUC 在 epoch 6 降至 0.7746
- 过拟合仍存在但略好于实验 1（下降幅度：5.7% → 5.6%）

2. **结果分析**
- 升级正则后最佳 AUC 略升（0.8183 → 0.8205）
- 过拟合速度稍放缓，但仍在 epoch 2 见顶
- 说明正则化力度仍不足 & 学习率过大

3. **优化思路**
- 再次抑制过拟合：
  1. **降低学习率** (0.001 → 0.0005)
  2. **进一步增大 dropout** (0.3 → 0.4)
  3. 适当缩短 Early-Stopping patience (10 → 7)

4. **参数调整**
| 参数 | 调整前 | 调整后 |
|------|--------|--------|
| lr_kt_pretrain | 0.001 | **0.0005** |
| lr_kt_finetune | 0.0005 | **0.00025** |
| dropout | 0.3 | **0.4** |
| patience | 10 | **7** |

---

## 实验 3  （dropout 0.4 + lr 0.0005 + patience 7）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist09 --n_runs 5
```

1. **关键结果**
- Dropout 0.4，L2 1e-4，lr 0.0005
- 最佳 Val AUC = **0.8146** @ epoch 2
- Val AUC 在 epoch 3 降至 0.8082
- 训练在第4个epoch被中断（用户手动停止）

2. **结果分析**
- 降低学习率和增大dropout后，**过拟合问题依旧**，模型仍然在第2个epoch达到性能顶峰，然后迅速开始下降。
- 这说明简单的参数调整已达瓶颈，需要更高级的训练策略来稳定训练过程。

3. **优化思路**
- **引入学习率Warmup**：在训练初期使用一个非常小的学习率，然后逐渐增加到设定的初始学习率。这有助于模型在训练初期找到一个更稳定的收敛方向，避免过早陷入局部最优或过拟合。
- **使用学习率衰减（Scheduler）**：在Warmup之后，如果验证集性能在一定轮次内没有提升，就自动降低学习率，进行更精细的调优。

4. **参数调整**
| 参数 | 调整前 | 调整后 |
|------|--------|--------|
| `lr_kt_pretrain` | 0.0005 | **保持 0.0005** |
| `warmup_steps` | - | **4000** (约半个epoch) |
| `lr_scheduler` | - | **ReduceLROnPlateau** |
| `lr_decay_patience` | - | **3** |
| `lr_decay_factor` | - | **0.5** |

> **TODO 实验 4**：运行以上新参数，完成后补充结果。

---

## 实验 A17-1  （ASSIST17 baseline - 速度问题）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist17 --n_runs 5
```

1. **配置**
- max_seq_len: 200
- batch_size: 32
- dropout: 0.2
- 硬件: RTX 3060 Laptop GPU

2. **关键结果**
- 训练速度: **3.5 小时/epoch** ❌ 极慢！
- Val AUC: 0.7630 → 0.7723 → 0.7774（稳步提升）✓
- 无过拟合现象 ✓
- 速度: 1.6-1.8 it/s

3. **结果分析**
- ASSIST17 平均序列长度 **551.7**（是ASSIST09的7倍）
- 20,546 个batch/epoch（是ASSIST09的3倍）
- 注意力机制复杂度：O(seq_len²)，200² = 40,000
- **预计 100 epochs 需要 350 小时（14.6天）** ❌ 不可接受
- **根本原因**：长序列导致注意力计算爆炸

4. **优化思路**
- **关键瓶颈**：序列长度的平方复杂度
- **解决方案**：
  1. 截断序列：200 → 100（预期提速 3-4倍）⭐⭐⭐
  2. 增大batch：32 → 64（预期提速 1.25倍）⭐⭐
  3. 减少图更新：每10 → 每50 batch（预期提速 1.1倍）⭐
  4. 减少轮数：100 → 50 epochs（先验证效果）
- **综合预期提速**：5-7倍（3.5小时 → 30-40分钟）

5. **参数调整**
| 参数 | 原值 | 调整后 | 理由 |
|------|------|--------|------|
| max_seq_len | 200 | **100** | 关键：减少注意力计算量（O(n²)）|
| batch_size | 32 | **64** | 提升GPU并行度 |
| n_epochs | 100 | **50** | 先验证50轮效果 |
| concept_update_freq | 10 | **50** | 减少图卷积计算 |

---

## 实验 A17-2  （速度优化版 - 台式机RTX 5070 Ti）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist17 --n_runs 5
```

1. **配置（已优化）**
- max_seq_len: **100** ⭐
- batch_size: **96** ⭐ (台式机配置)
- dropout: **0.2**
- n_epochs: **50**
- patience: **10**
- concept_update_freq: **50** ⭐
- 硬件: **RTX 5070 Ti** (更强GPU)

2. **关键结果**
- 训练速度: **30-34 分钟/epoch** ✓ (提速约6-7倍)
- Batch数: **6,849/epoch**
- 速度: **3.4-4.1 it/s** ✓
- **Run 1**: 峰值 Val AUC = **0.7804** @ epoch 5, Test AUC = **0.7664**, Early Stop @ epoch 15
- **Run 2**: 峰值 Val AUC = **0.7797** @ epoch 4, Test AUC = **0.7667**, Early Stop @ epoch 14
- **Run 3**: 峰值 Val AUC = **0.7791** @ epoch 5 (进行中)
- **平均 Test AUC**: **0.7665** (Run 1-2)

3. **结果分析**

**✅ 速度优化成功**：
- 从3.5小时/epoch → 30-34分钟/epoch（**提速6-7倍**）
- 单次运行约7-8小时（Early Stop在15轮触发）
- 5次运行约35-40小时（1.5天，可接受）

**❌ 性能问题严重**：
- **明显过拟合**：峰值在Epoch 4-5，之后持续下降（0.780 → 0.752，下降2.8%）
- **性能未达预期**：Test AUC 0.7665 vs 论文预期 0.78-0.79（差距1.5-2.5%）
- **训练损失与验证性能背离**：训练损失持续下降（0.613 → 0.500），但验证AUC在下降

**🔍 根本原因**：
1. **max_seq_len=100 太短**：
   - ASSIST17平均序列长度551.7
   - 只保留了18%的序列信息
   - 丢失大量长期依赖 → 性能上限降低

2. **batch_size=96 太大**：
   - 更大batch → 更稳定梯度 → 更容易过拟合
   - 泛化能力下降

3. **dropout=0.2 正则化不足**：
   - ASSIST17序列更长、更复杂
   - 需要更强的正则化（建议0.3）

4. **patience=10 太保守**：
   - 峰值在Epoch 4-5
   - Early Stop在Epoch 14-15触发
   - 在峰值后又训练了10个epoch（都在过拟合）

4. **优化思路**

**核心矛盾**：速度与性能的权衡
- max_seq_len=200：性能好但太慢（3.5小时/epoch）
- max_seq_len=100：快但性能差（0.7665 vs 0.79）
- **解决方案**：max_seq_len=150（平衡点）

**具体策略**：
1. **适度增加序列长度**：100 → 150（保留27%信息，预期+0.01-0.015 AUC）
2. **降低batch size**：96 → 64（增强泛化，预期+0.003-0.005 AUC）
  3. **增强正则化**：dropout 0.2 → 0.3（减轻过拟合，预期+0.005-0.010 AUC）
  4. **更激进Early Stop**：patience 10 → 5（在峰值后5轮停止，预期+0.002-0.005 AUC）
  5. **添加L2正则化**：l2_lambda=1e-5（轻度正则化，减轻过拟合）

**注意**：不添加Warmup和LR Scheduler，原因：
- ✅ 论文中未使用，保持一致性
- ✅ ASSIST17训练已经稳定（前5个epoch稳步上升）
- ✅ 问题在于过拟合而非训练初期不稳定
- ✅ 简化实验变量，便于分析

**预期综合提升**：+0.020-0.030 AUC → **Test AUC 0.785-0.795** ✓

5. **参数调整**
| 参数 | A17-2 | A17-3 (优化) | 理由 |
|------|-------|--------------|------|
| max_seq_len | 100 | **150** | 平衡性能与速度（保留更多序列信息）|
| batch_size | 96 | **64** | 增强泛化能力 |
| dropout | 0.2 | **0.3** | 加强正则化，减轻过拟合 |
| patience | 10 | **5** | 更激进的Early Stopping |
| n_epochs | 50 | **30** | Early Stop通常在15触发，减少无效训练 |
| l2_lambda | - | **1e-5** | 新增L2正则化 |

**预期效果**：
- 训练速度: **45分钟/epoch**（比A17-2慢1.5倍，但仍可接受）
- Early Stop: **Epoch 10左右**（比A17-2更早）
- 单次运行: **约7.5小时**（与A17-2相当）
- Test AUC: **0.785-0.795**（提升0.020-0.030）✓

---

## 实验 A17-3  （性能优化版 - 待运行）

0. **运行命令**
```bash
python experiments/run_experiment.py --dataset assist17 --n-runs 5
```

1. **配置（已优化）**
- max_seq_len: **150** ⭐ (平衡点)
- batch_size: **64** ⭐
- dropout: **0.3** ⭐
- n_epochs: **30**
- patience: **5** ⭐
- l2_lambda: **1e-5** (新增)
- warmup_steps: **2000** (新增)
- lr_decay_patience: **5** (新增)
- lr_decay_factor: **0.5** (新增)

2. **预期结果**
- 训练速度: **45分钟/epoch**
- Early Stop: **Epoch 10左右**
- 单次运行: **约7.5小时**
- 5次运行: **约37.5小时（1.5天）**
- 峰值 Val AUC: **0.790±0.005**
- Test AUC: **0.785-0.795** ✓ (达到论文要求)

3. **验证指标**
运行完成后，检查：
- [ ] Test AUC ≥ 0.785（性能达标）
- [ ] Early Stop在Epoch 8-12触发（过拟合减轻）
- [ ] 峰值后AUC下降 < 0.015（过拟合控制）
- [ ] 训练时间 < 8小时/次（速度可接受）

> **TODO 实验 A17-3**：使用优化配置重新运行。完成后补充实际结果。
