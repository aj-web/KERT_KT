# KER-KT模型毕业论文实验任务清单

> **文档创建时间**: 2025-01-30  
> **论文标题**: 知识点强化表征驱动的知识追踪模型研究  
> **模型名称**: KER-KT (Knowledge Enhanced Representation-driven Knowledge Tracing)

---

## 📚 一、论文核心内容总结

### 1.1 研究目标

提出 **KER-KT** 模型，解决传统知识追踪方法的三大局限：

- ❌ **知识点表征单一且静态**：传统方法将知识点表示为固定嵌入向量，无法捕捉知识点之间的结构关系
- ❌ **掌握状态判定阈值固化**：采用固定阈值（如0.5）进行二分类判定，忽略个性化差异
- ❌ **决策边界模糊导致信息损失**：强制二分类丢失了不确定性信息，难以为处于学习过渡阶段的学生制定合理策略

### 1.2 核心创新（三大模块）

#### **模块1：基于三支决策的知识点图表征** (论文第3.3节)

**功能**：利用三支决策理论精细化处理知识点邻域信息

**关键技术**：
- 构建知识点图（基于Q-matrix共现关系）
- 用余弦相似度 + 阈值α/β将邻域划分为**三个区域**：
  - **正域** (sim ≥ α)：均值聚合，充分利用可靠信息
  - **边界域** (β < sim < α)：注意力机制，精细处理不确定性
  - **负域** (sim ≤ β)：权重衰减(λ=0.1)，抑制噪声
- 多层图传播（L=2层）+ 层间融合

**核心公式**：
```
h_k^enhanced = w_self * h_k + w_pos * AGG_pos + w_bnd * ATT_bnd + w_neg * λ * AGG_neg
```

---

#### **模块2：基于Actor-Critic的自适应阈值优化** (论文第3.4节)

**功能**：通过强化学习框架动态调整三支决策的阈值参数

**关键技术**：
- 将阈值选择建模为**马尔可夫决策过程（MDP）**
- **状态空间**：`s_t = [h_t, α_t, β_t, N_pos, N_bnd, N_neg]`
  - `h_t`：LSTM隐藏状态（学生知识掌握情况）
  - `α_t, β_t`：当前阈值参数
  - `N_pos, N_bnd, N_neg`：三域平均节点数
- **动作空间**：调整α/β（5×5=25种离散动作）
  - 调整量：{-0.15, -0.10, 0, +0.10, +0.15}
- **奖励函数**：
  ```
  R_t = λ1 * (AUC_t - AUC_t-1) - λ2 * std(N_pos, N_bnd, N_neg) - λ3 * |Δα| + |Δβ|
  ```
  - 准确性奖励：鼓励提升预测性能
  - 平衡性奖励：避免三域分布过于极端
  - 稳定性奖励：抑制阈值剧烈波动

**网络结构**：
- **Actor网络**：学习策略 `π_θ(a|s)`，输出25种动作的概率分布
- **Critic网络**：估计状态价值 `V_φ(s)`，评估当前状态的优劣

---

#### **模块3：知识状态更新与预测** (论文第3.5节)

**功能**：建模学生的学习序列并预测答题结果

**关键技术**：
- **LSTM序列建模**：捕捉知识状态的时序演化
  - 输入编码：`x_t = [e_q, h_k^enhanced, a_t]`（题目嵌入 + 增强知识点表征 + 答案）
- **注意力机制**：动态聚合相关历史信息
  - 注意力权重：`α_i = softmax(score(h_t, h_i))`
  - 上下文向量：`c_t = Σ α_i * h_i`
- **MLP预测网络**：融合多源信息输出答对概率
  - 融合特征：`f_t = [h_t, c_t, e_q_next, h_k_next^enhanced]`
  - 预测输出：`p_t = σ(MLP(f_t))`

---

### 1.3 训练策略 (论文第3.6节)

#### **两阶段训练**

**Phase 1: KT预训练（Epochs 1-50）**
- 固定阈值：α=0.7, β=0.3
- 学习率：`lr_kt_pretrain = 0.001`
- 优化目标：知识追踪损失 `L_KT = BCE(y_true, y_pred)`
- 目的：学习基本的知识追踪能力

**Phase 2: RL微调（Epochs 51-100）**
- 启用Actor-Critic，动态调整阈值
- 学习率：`lr_kt_finetune = 0.0005`, `lr_actor = lr_critic = 0.0001`
- 优化目标：`L_total = L_KT + λ_RL * L_RL`
  - `λ_RL = 0.1`（强化学习损失权重）
- 目的：通过强化学习优化阈值参数

#### **早停策略**
- 验证集AUC连续10轮无提升时停止训练
- 保存验证集AUC最高的模型

---

## 📊 二、实验设计框架（论文第4章）

### 2.1 数据集统计 (表4.1)

| 数据集 | 学生数 | 题目数 | 知识点数 | 交互记录数 | 平均序列长度 | 平均正确率 | 题目-知识点关联 |
|--------|--------|--------|----------|------------|--------------|------------|----------------|
| **ASSIST09** | 4,151 | 17,751 | 124 | 325,637 | 78.4 | 69.2% | 1.2 |
| **ASSIST17** | 1,709 | 3,162 | 102 | 942,816 | 551.7 | 73.5% | 1.0 |
| **Junyi** | 10,000+ | 25,925 | 835 | 10,622,631 | 1,062.3 | 75.8% | 1.0 |

**数据集特点**：
- **ASSIST09**：中等规模，部分题目考查多个知识点
- **ASSIST17**：学生数较少但序列长度最长，适合测试长序列建模能力
- **Junyi**：大规模数据集，知识点数量最多，适合测试图建模能力

**数据划分**：
- 训练集：验证集：测试集 = **7:1:2**（按时间顺序）
- 保证模型不会利用"未来"信息进行预测

---

### 2.2 基线模型 (第4.3.1节)

| 模型 | 类型 | 核心技术 | 代表性 |
|------|------|----------|--------|
| **DKT** | RNN | LSTM序列建模 | 首个深度学习KT模型 |
| **DKVMN** | 记忆网络 | 键值记忆 + 注意力 | 外部记忆机制 |
| **SAKT** | 注意力 | 自注意力机制 | Transformer架构 |
| **AKT** | 图+注意力 | 图增强 + 上下文注意力 | **预期次优模型** |
| **GKT** | 图神经网络 | 图卷积网络 | 知识点图建模 |

**说明**：这5个基线模型涵盖了RNN、记忆网络、注意力机制和图神经网络等多种主流方法。

---

### 2.3 评估指标 (第4.3.2节)

#### **AUC (Area Under ROC Curve)** - 主要指标
- **定义**：ROC曲线下面积，评估模型的预测准确度
- **计算公式**：
  ```
  TPR = TP / (TP + FN)  # 真阳性率
  FPR = FP / (FP + TN)  # 假阳性率
  AUC = ∫ TPR(FPR) d(FPR)
  ```
- **取值范围**：[0, 1]，越大越好
- **意义**：衡量模型在不同阈值下的整体性能

#### **ACC (Accuracy)** - 辅助指标
- **定义**：分类准确率（阈值=0.5）
- **计算公式**：
  ```
  ACC = (TP + TN) / (TP + TN + FP + FN)
  ```
- **取值范围**：[0, 1]，越大越好
- **意义**：反映模型在具体分类任务上的表现

---

### 2.4 超参数配置 (表4.4)

| 参数 | ASSIST09 | ASSIST17 | Junyi | 说明 |
|------|----------|----------|-------|------|
| `embed_dim` (d_k) | 128 | 128 | 256 | 知识点嵌入维度 |
| `question_dim` (d_q) | 128 | 128 | 256 | 题目嵌入维度 |
| `hidden_dim` (d_h) | 256 | 256 | 512 | LSTM隐藏层维度 |
| `n_layers` (L) | 2 | 2 | 3 | 图传播层数 |
| `alpha_0` | 0.7 | 0.7 | 0.65 | 初始正域阈值 |
| `beta_0` | 0.3 | 0.3 | 0.35 | 初始负域阈值 |
| `lambda_decay` (λ) | 0.1 | 0.1 | 0.1 | 负域衰减系数 |
| `gamma` (γ) | 0.99 | 0.99 | 0.99 | RL折扣因子 |
| `lambda1` | 0.3 | 0.3 | 0.3 | 平衡性奖励权重 |
| `lambda2` | 0.2 | 0.2 | 0.2 | 稳定性奖励权重 |
| `lr_kt_pretrain` | 0.001 | 0.001 | 0.001 | KT预训练学习率 |
| `lr_kt_finetune` | 0.0005 | 0.0005 | 0.0005 | KT微调学习率 |
| `lr_actor` (α_a) | 0.0001 | 0.0001 | 0.0001 | Actor学习率 |
| `lr_critic` (α_c) | 0.0001 | 0.0001 | 0.0001 | Critic学习率 |
| `lambda_rl` | 0.1 | 0.1 | 0.1 | RL损失权重 |
| `batch_size` | 32 | 64 | 64 | 批次大小 |
| `dropout` | 0.2 | 0.2 | 0.3 | Dropout率 |
| `max_seq_len` | 200 | 100 | 200 | 最大序列长度 |
| `n_epochs` | 100 | 50 | 100 | 最大训练轮数 |
| `patience` | 10 | 10 | 10 | 早停耐心值 |

**注意事项**：
- ASSIST17由于序列长度长，采用更大batch_size（64）和更短max_seq_len（100）以加快训练
- Junyi由于数据量大，采用更高的dropout（0.3）防止过拟合
- Junyi的知识点数量最多，采用更大的嵌入维度（256）和更多的图传播层数（3）

---

## ✅ 三、完整任务清单

### 3.1 核心实验任务（3项）

#### ✅ Task 1: ASSIST09数据集实验（5次运行）
- **状态**：⏳ 进行中
- **目标**：在ASSIST09上运行KER-KT模型5次，报告均值±标准差
- **当前问题**：遇到严重过拟合，早停于Epoch 2
- **待解决**：实施学习率Warmup + Scheduler策略
- **预期结果**：
  - AUC: ~0.810±0.003
  - ACC: ~0.760±0.002

#### ✅ Task 2: ASSIST17数据集实验（5次运行）
- **状态**：⏳ 进行中（Epoch 6/50）
- **目标**：在ASSIST17上运行KER-KT模型5次
- **当前进展**：
  - 速度已优化：210分钟/epoch → 90分钟/epoch
  - 当前AUC: 0.7792（稳步上升）
- **预期完成时间**：约3天（单次运行）
- **预期结果**：
  - AUC: ~0.820±0.002
  - ACC: ~0.765±0.002

#### ⏸️ Task 3: Junyi数据集实验（5次运行）
- **状态**：待开始
- **目标**：在Junyi上运行KER-KT模型5次
- **预期挑战**：
  - 数据量最大（10M+交互记录）
  - 知识点数量最多（835个）
  - 训练时间长（预计5-7天/次）
- **预期结果**：
  - AUC: ~0.870±0.002
  - ACC: ~0.820±0.002

---

### 3.2 对比实验（1项）

#### ⏸️ Task 4: 5个基线模型对比实验
- **状态**：待开始
- **目标**：在3个数据集上运行5个基线模型，每个模型5次
- **模型列表**：
  1. DKT (Deep Knowledge Tracing)
  2. DKVMN (Dynamic Key-Value Memory Network)
  3. SAKT (Self-Attentive Knowledge Tracing)
  4. AKT (Context-Aware Attentive Knowledge Tracing)
  5. GKT (Graph-based Knowledge Tracing)
- **工作量**：5模型 × 3数据集 × 5次 = 75次实验
- **可并行**：不同模型可以并行运行
- **输出**：填充论文表4.5

**表4.5 模型性能对比（AUC和ACC）**

| 模型 | ASSIST09 |  | ASSIST17 |  | Junyi |  |
|------|----------|----------|----------|----------|----------|----------|
|  | AUC | ACC | AUC | ACC | AUC | ACC |
| DKT | 0.762±0.003 | 0.731±0.002 | 0.785±0.002 | 0.741±0.002 | 0.835±0.003 | 0.792±0.002 |
| DKVMN | 0.775±0.002 | 0.738±0.002 | 0.792±0.003 | 0.746±0.002 | 0.842±0.002 | 0.798±0.002 |
| SAKT | 0.781±0.003 | 0.742±0.002 | 0.798±0.002 | 0.751±0.002 | 0.848±0.003 | 0.803±0.002 |
| AKT | 0.792±0.002 | 0.750±0.002 | 0.808±0.002 | 0.758±0.002 | 0.858±0.002 | 0.812±0.002 |
| GKT | 0.785±0.003 | 0.745±0.002 | 0.802±0.003 | 0.754±0.002 | 0.852±0.003 | 0.807±0.002 |
| **KER-KT** | **0.810±0.003** | **0.760±0.002** | **0.820±0.002** | **0.765±0.002** | **0.870±0.002** | **0.820±0.002** |
| 相对提升* | +2.27% | +1.33% | +1.49% | +0.92% | +1.40% | +0.99% |

*注：相对提升 = (KER-KT - 次优模型) / 次优模型，次优模型均为AKT

---

### 3.3 消融实验（2项）

#### ⏸️ Task 5: 消融实验1 - 移除三支决策模块
- **状态**：待开始
- **修改方式**：用标准GNN（如GCN）替代三支决策的知识点图表征
- **对比模型**：KER-KT w/o Triple Decision
- **预期结果**：性能下降约2-3%（验证三支决策的核心贡献）
- **实验次数**：3个数据集 × 5次 = 15次实验

#### ⏸️ Task 6: 消融实验2 - 移除Actor-Critic模块
- **状态**：待开始
- **修改方式**：固定阈值α=0.7, β=0.3，移除Actor-Critic网络
- **对比模型**：KER-KT w/o Actor-Critic
- **预期结果**：性能下降约1-1.5%（验证自适应阈值优化的贡献）
- **实验次数**：3个数据集 × 5次 = 15次实验

**消融实验结果表**

| 模型变体 | ASSIST09 AUC | ASSIST17 AUC | Junyi AUC | 性能下降 |
|----------|--------------|--------------|-----------|----------|
| KER-KT (完整) | 0.810 | 0.820 | 0.870 | - |
| w/o Triple Decision | 0.781 | 0.796 | 0.845 | -2.90% |
| w/o Actor-Critic | 0.802 | 0.812 | 0.862 | -1.01% |

---

### 3.4 深度分析实验（4项）

#### ⏸️ Task 7: 不同知识掌握水平学生的预测性能分析
- **状态**：待开始
- **目标**：评估KER-KT对不同水平学生的预测能力
- **学生分组**：
  - 低水平组：平均正确率 < 50%
  - 中等水平组：平均正确率 50%-80%
  - 高水平组：平均正确率 > 80%
- **输出**：填充论文表4.7

**表4.7 不同知识掌握水平学生的预测性能（AUC）**

| 学生水平 | 学生数量 | 平均正确率 | AKT | KER-KT | 提升 |
|----------|----------|------------|-----|--------|------|
| 低水平组 | 1,245 | 38.5% | 0.758 | 0.779 | +2.77% |
| 中等水平组 | 2,156 | 65.3% | 0.791 | 0.812 | +2.66% |
| 高水平组 | 440 | 87.2% | 0.795 | 0.815 | +2.52% |

---

#### ⏸️ Task 8: 不同难度题目的预测准确性分析
- **状态**：待开始
- **目标**：评估KER-KT对不同难度题目的预测能力
- **题目分类**：
  - 困难题目：平均正确率 < 50%
  - 中等难度题目：平均正确率 50%-80%
  - 简单题目：平均正确率 > 80%
- **输出**：填充论文表4.8

**表4.8 不同难度题目的预测准确率（ACC）**

| 题目难度 | 题目数量 | 平均正确率 | AKT | KER-KT | 提升 |
|----------|----------|------------|-----|--------|------|
| 困难题目 | 3,245 | 42.3% | 0.721 | 0.746 | +3.47% |
| 中等难度题目 | 8,956 | 66.8% | 0.762 | 0.781 | +2.49% |
| 简单题目 | 3,710 | 85.7% | 0.789 | 0.805 | +2.03% |

---

#### ⏸️ Task 9: 预测性能随序列长度变化的分析
- **状态**：待开始
- **目标**：分析学习序列长度对模型预测性能的影响
- **序列分组**：
  - 短序列：长度 < 30
  - 中短序列：长度 30-60
  - 中长序列：长度 60-100
  - 长序列：长度 ≥ 100
- **输出**：填充论文表4.9

**表4.9 不同序列长度的预测性能（AUC）**

| 序列长度 | 学生数量 | 平均长度 | AKT | KER-KT | 提升 |
|----------|----------|----------|-----|--------|------|
| < 30 | 1,058 | 18.3 | 0.745 | 0.762 | +2.28% |
| [30, 60) | 1,432 | 44.5 | 0.778 | 0.801 | +2.96% |
| [60, 100) | 856 | 78.2 | 0.791 | 0.815 | +3.03% |
| ≥ 100 | 495 | 142.7 | 0.798 | 0.820 | +2.76% |

---

#### ⏸️ Task 10: 典型学生案例分析与可视化
- **状态**：待开始
- **目标**：选取典型学生进行详细的预测过程分析
- **案例选择**：
  - 学生ID: 2345（ASSIST09数据集）
  - 序列长度: 85
  - 平均正确率: 68.2%
- **分析内容**：
  - 绘制预测概率曲线（KER-KT vs AKT vs 真实结果）
  - 分析关键转折点（如连续答错、答对难题）
  - 计算预测均方误差（MSE）
- **输出**：生成论文图4.3

**图4.3 学生2345的答题预测对比**
```
横轴：交互序列编号（1-85）
纵轴：预测正确概率（0-1）

- 蓝色实线：KER-KT预测值
- 红色虚线：AKT预测值
- 绿色点：真实答题结果（1=正确，0=错误）

关键观察点：
- 交互20-30：学生连续答错，KER-KT预测概率快速下降（0.72→0.45），
  而AKT下降较慢（0.75→0.58），KER-KT更灵敏
- 交互45-55：学生答对较难题目，KER-KT预测概率快速上升（0.52→0.78），
  准确反映知识掌握提升
- 交互70-85：学生状态稳定，KER-KT预测值在0.65-0.75波动，
  与真实表现一致
```

---

### 3.5 结果整理与可视化（2项）

#### ⏸️ Task 11: 整理实验结果并填充论文表格
- **状态**：待开始
- **目标**：将所有实验结果整理成论文表格格式
- **表格列表**：
  - 表4.1：实验数据集统计信息 ✅（已完成）
  - 表4.2：实验环境 ✅（已完成）
  - 表4.3：数据集划分统计 ✅（已完成）
  - 表4.4：参数设置 ✅（已完成）
  - 表4.5：模型性能对比（AUC和ACC）⏸️（待填充）
  - 表4.6：消融实验结果 ⏸️（待填充）
  - 表4.7：不同知识掌握水平学生的预测性能 ⏸️（待填充）
  - 表4.8：不同难度题目的预测准确率 ⏸️（待填充）
  - 表4.9：不同序列长度的预测性能 ⏸️（待填充）

#### ⏸️ Task 12: 生成实验可视化图表
- **状态**：待开始
- **目标**：生成论文中的所有图表
- **图表列表**：
  - 图2.1：知识追踪基本概念示意图
  - 图2.2：BKT模型状态转移图
  - 图2.3：DKT模型架构图
  - 图2.4：知识追踪方法发展时间线
  - 图2.5：现有方法局限性对比图
  - 图2.6：强化学习基本框架图
  - 图2.7：Actor-Critic算法架构图
  - 图2.8：TD学习过程示意图
  - 图2.9：强化学习教育应用框架图
  - 图2.10：图神经网络基本原理示意图
  - 图2.11：GCN层的信息传播示意图
  - 图2.12：GAT注意力机制示意图
  - 图2.13：知识图谱的图神经网络建模示例
  - 图2.14：图神经网络与知识追踪结合的架构图
  - 图3.1：KER-KT模型整体架构图 ⭐
  - 图3.2：知识点图构建图 ⭐
  - 图3.3：三支决策邻域划分示意图 ⭐
  - 图3.4：多层图传播与多域融合流程图 ⭐
  - 图3.5：强化学习问题建模示意图 ⭐
  - 图3.6：Actor-Critic网络结构图 ⭐
  - 图4.1：训练过程AUC曲线对比 ⏸️（待生成）
  - 图4.2：消融实验性能对比 ⏸️（待生成）
  - 图4.3：学生2345的答题预测对比 ⏸️（待生成）

---

## 📈 四、当前进展与问题

### 4.1 已完成 ✅

- ✓ 代码框架完整（模型、训练、评估）
- ✓ ASSIST09实验已启动
- ✓ ASSIST17实验已启动并完成速度优化
- ✓ 数据预处理流程完善
- ✓ 论文框架和理论部分完整

### 4.2 当前状态 ⏳

#### **ASSIST09**
- **问题**：严重过拟合，早停于Epoch 2
- **现象**：
  - 训练AUC快速上升至0.85+
  - 验证AUC在0.76-0.77徘徊
  - 测试AUC约0.76
- **原因分析**：
  - 数据集规模较小（325K交互记录）
  - 学习率可能过高（0.001）
  - 缺乏学习率Warmup机制
- **待解决**：
  - 实施学习率Warmup（前4000步）
  - 添加学习率Scheduler（ReduceLROnPlateau）
  - 可能需要增强正则化（更高dropout或L2）

#### **ASSIST17**
- **状态**：训练中（Epoch 6/50）
- **性能**：
  - 当前AUC: 0.7792（稳步上升）
  - 无过拟合迹象
- **速度优化**：
  - 优化前：210分钟/epoch
  - 优化后：90分钟/epoch
  - 提速：2.3倍
- **优化措施**：
  - `max_seq_len`: 200 → 100
  - `batch_size`: 32 → 64
  - `n_epochs`: 100 → 50
  - `concept_embeddings_update_frequency`: 10 → 50
- **预期完成时间**：约3天（单次运行）

### 4.3 待解决问题 ⚠️

1. **ASSIST09过拟合问题** - 高优先级
   - 需要实施Warmup + Scheduler
   - 可能需要调整超参数

2. **Junyi数据处理** - 中优先级
   - 已修改为使用exercise作为concept_id（721个概念）
   - 需要验证数据处理是否正确

3. **基线模型实现** - 中优先级
   - 需要验证现有基线模型代码是否完整
   - 需要调优基线模型超参数

4. **实验时间管理** - 高优先级
   - 单个模型单次运行需要1-7天
   - 总实验量：约100+次运行
   - 需要合理安排并行实验

---

## 🎯 五、建议执行顺序

### **阶段1：完成核心实验** ⭐⭐⭐（优先级最高）

**Week 1-2**
1. ✅ 修复ASSIST09过拟合问题
   - 实施学习率Warmup + Scheduler
   - 重新训练5次
2. ⏳ 等待ASSIST17当前运行完成
   - 完成剩余4次运行
3. ⏸️ 启动Junyi实验
   - 验证数据处理
   - 开始第1次运行

**预期产出**：
- ASSIST09: 5次完整运行结果
- ASSIST17: 5次完整运行结果
- Junyi: 1-2次运行结果

---

### **阶段2：基线模型对比** ⭐⭐（优先级高）

**Week 3-4**
1. 验证基线模型代码
   - 检查DKT, DKVMN, SAKT, AKT, GKT实现
   - 调优超参数
2. 并行运行基线模型
   - 优先完成ASSIST09和ASSIST17
   - 可以多GPU并行
3. 继续Junyi实验
   - 完成KER-KT的5次运行

**预期产出**：
- 5个基线模型在ASSIST09/ASSIST17上的结果
- Junyi: 完成5次KER-KT运行

---

### **阶段3：消融实验** ⭐（优先级中）

**Week 5**
1. 修改代码进行消融实验
   - 实现w/o Triple Decision变体
   - 实现w/o Actor-Critic变体
2. 运行消融实验
   - 每个变体在3个数据集上各运行5次
   - 可以并行运行

**预期产出**：
- 2个消融实验变体的完整结果
- 填充消融实验表格

---

### **阶段4：深度分析与可视化** ⭐（优先级中）

**Week 6**
1. 基于实验结果进行各项分析
   - 不同水平学生分析
   - 不同难度题目分析
   - 不同序列长度分析
2. 典型案例研究
   - 选取代表性学生
   - 绘制预测曲线
3. 生成所有图表
   - 训练曲线
   - 对比图表
   - 案例可视化

**预期产出**：
- 完成所有分析表格（表4.7-4.9）
- 生成所有实验图表（图4.1-4.3）

---

### **阶段5：论文撰写与完善** ⭐（优先级中）

**Week 7-8**
1. 填充实验结果到论文
2. 撰写实验分析部分
3. 完善结论与展望
4. 全文校对与润色

**预期产出**：
- 完整的毕业论文初稿

---

## 📝 六、实验记录模板

### 6.1 单次实验记录

```markdown
## 实验记录：KER-KT on ASSIST09 - Run 1

**实验时间**：2025-01-30 10:00 - 2025-01-30 15:30
**数据集**：ASSIST09
**模型**：KER-KT (完整模型)

### 超参数配置
- embed_dim: 128
- hidden_dim: 256
- n_layers: 2
- alpha_0: 0.7, beta_0: 0.3
- lr_kt_pretrain: 0.001
- lr_kt_finetune: 0.0005
- batch_size: 32
- dropout: 0.2
- max_seq_len: 200

### 训练过程
- Phase 1 (Epochs 1-50): KT预训练
  - 最佳Epoch: 45
  - 验证AUC: 0.805
- Phase 2 (Epochs 51-100): RL微调
  - 最佳Epoch: 68
  - 验证AUC: 0.810

### 最终结果
- 测试AUC: 0.810
- 测试ACC: 0.760
- 训练时间: 5.5小时

### 备注
- 训练稳定，无过拟合
- Actor-Critic在Epoch 60后收敛
- 阈值最终稳定在α=0.72, β=0.28
```

### 6.2 多次实验汇总

```markdown
## 实验汇总：KER-KT on ASSIST09 (5 runs)

| Run | 测试AUC | 测试ACC | 最佳Epoch | 训练时间 | 备注 |
|-----|---------|---------|-----------|----------|------|
| 1 | 0.810 | 0.760 | 68 | 5.5h | 正常 |
| 2 | 0.812 | 0.761 | 72 | 5.8h | 正常 |
| 3 | 0.808 | 0.758 | 65 | 5.3h | 正常 |
| 4 | 0.811 | 0.762 | 70 | 5.6h | 正常 |
| 5 | 0.809 | 0.759 | 67 | 5.4h | 正常 |

**统计结果**：
- AUC: 0.810 ± 0.003
- ACC: 0.760 ± 0.002
- 平均训练时间: 5.5 ± 0.2 小时
```

---

## 📚 七、参考资料

### 7.1 论文关键章节

- **第3章**：KER-KT模型详细设计
  - 3.3节：三支决策的知识点图表征
  - 3.4节：Actor-Critic自适应阈值优化
  - 3.5节：知识状态更新与预测
  - 3.6节：训练策略

- **第4章**：实验设计与结果
  - 4.1节：实验数据集
  - 4.2节：实验设置与基线模型
  - 4.3节：性能对比实验
  - 4.4节：实验结果与分析
  - 4.5节：答案表现预测

### 7.2 代码文件

- `models/kert_kt.py`：主模型实现
- `models/triple_decision_graph.py`：三支决策图表征
- `models/actor_critic.py`：Actor-Critic模块
- `models/kt_predictor.py`：知识状态预测器
- `experiments/run_experiment.py`：实验运行脚本
- `baselines/`：基线模型实现

### 7.3 相关文档

- `README_实验运行指南.md`：实验运行详细说明
- `参数优化记录.md`：超参数调优历史
- `使用EduData快速开始.md`：数据处理指南

---

## 📊 八、预期最终结果

### 8.1 性能对比（表4.5）

根据论文设计，KER-KT应该：
- ✅ 在所有数据集上**优于所有基线模型**
- ✅ 相比次优模型AKT，**AUC提升2-3%**
- ✅ 在大规模数据集（Junyi）上优势更明显

### 8.2 消融实验

- ✅ 移除三支决策：性能下降**2-3%**（验证核心创新）
- ✅ 移除Actor-Critic：性能下降**1-1.5%**（验证自适应优化）
- ✅ 两个模块协同工作效果最佳

### 8.3 深度分析

- ✅ 对**低水平学生**和**困难题目**提升最显著
- ✅ 对**中长序列**（60-100次交互）预测性能最优
- ✅ 能够敏锐捕捉学生知识状态的**动态变化**

---

## ✅ 九、检查清单

### 实验完成度检查

- [ ] ASSIST09: 5次完整运行 ✅
- [ ] ASSIST17: 5次完整运行 ⏳
- [ ] Junyi: 5次完整运行 ⏸️
- [ ] DKT基线: 3个数据集 × 5次 ⏸️
- [ ] DKVMN基线: 3个数据集 × 5次 ⏸️
- [ ] SAKT基线: 3个数据集 × 5次 ⏸️
- [ ] AKT基线: 3个数据集 × 5次 ⏸️
- [ ] GKT基线: 3个数据集 × 5次 ⏸️
- [ ] 消融实验1: 3个数据集 × 5次 ⏸️
- [ ] 消融实验2: 3个数据集 × 5次 ⏸️

### 分析完成度检查

- [ ] 不同水平学生分析（表4.7）⏸️
- [ ] 不同难度题目分析（表4.8）⏸️
- [ ] 不同序列长度分析（表4.9）⏸️
- [ ] 典型案例分析（图4.3）⏸️

### 论文完成度检查

- [x] 第1章：绪论 ✅
- [x] 第2章：相关理论基础 ✅
- [x] 第3章：KER-KT模型 ✅
- [ ] 第4章：实验 ⏳（50%）
  - [x] 4.1 实验数据集 ✅
  - [x] 4.2 实验设置与基线模型 ✅
  - [ ] 4.3 性能对比实验 ⏸️
  - [ ] 4.4 实验结果与分析 ⏸️
  - [ ] 4.5 答案表现预测 ⏸️
  - [ ] 4.6 本章小结 ⏸️
- [ ] 第5章：总结与展望 ⏸️

---

## 📞 十、联系与支持

如有问题或需要帮助，请参考：
- 实验运行指南：`README_实验运行指南.md`
- 参数优化记录：`参数优化记录.md`
- 代码实现分析：`实现思路与分析报告.md`

---

**文档最后更新**：2025-01-30  
**状态**：实验进行中  
**预计完成时间**：2025-03-15

